{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgmbFf13xIE9"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/11-langchain-expression-language.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/11-langchain-expression-language.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXNOCoWMxIE_"
      },
      "source": [
        "#### [LangChain Handbook](https://pinecone.io/learn/langchain)\n",
        "\n",
        "# LangChain Expression Language (LCEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrEs_SmfxIFA"
      },
      "source": [
        "The **L**ang**C**hain **E**xpression **L**anguage (LCEL) is a abstraction of some interesting Python concepts into a format that enables a \"minimalist\" code layer for building chains of LangChain components.\n",
        "\n",
        "LCEL comes with strong support for:\n",
        "\n",
        "1. Superfast development of chains.\n",
        "2. Advanced features such as streaming, async, parallel execution, and more.\n",
        "3. Easy integration with LangSmith and LangServe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VeuXicSJxIFA"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "    langchain==0.0.345 \\\n",
        "    anthropic==0.7.7 \\\n",
        "    cohere==4.37 \\\n",
        "    docarray==0.39.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX2772cyxIFB"
      },
      "source": [
        "## LCEL Syntax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd253CXpxIFB"
      },
      "source": [
        "To understand LCEL syntax let's first build a simple chain in typical Python syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PHH92daRxIFB"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatAnthropic\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "ANTHROPIC_API_KEY = \"\"\n",
        "\n",
        "if ANTHROPIC_API_KEY == \"<<YOUR_ANTHROPIC_API_KEY>>\":\n",
        "    raise ValueError(\"Please set your ANTHROPIC_API_KEY\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Give me small report about {topic}\"\n",
        ")\n",
        "model = ChatAnthropic(\n",
        "    model=\"claude-2.1\",\n",
        "    max_tokens_to_sample=512,\n",
        "    anthropic_api_key=ANTHROPIC_API_KEY\n",
        ")  # swap Anthropic for OpenAI with `ChatOpenAI` and `openai_api_key`\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_-expsrxIFC"
      },
      "source": [
        "In typical LangChain we would chain these together using an `LLMChain`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hX00gOOXxIFC",
        "outputId": "c0041366-ba46-495c-dca7-44539fe613c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here is a brief report on artificial intelligence (AI):\n",
            "\n",
            "Introduction\n",
            "- AI refers to computer systems that are designed to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. \n",
            "\n",
            "Major AI Techniques\n",
            "- Machine learning uses statistical techniques and neural networks to enable AI systems to improve at tasks with experience. Common techniques include deep learning, reinforcement learning, and supervised learning.\n",
            "- Computer vision involves enabling AI systems to identify and process images/videos at human-level performance. Key applications include image recognition, video analysis, and medical imaging.\n",
            "- Natural language processing focuses on enabling AI systems to process, analyze, and generate human languages. Key applications include machine translation, sentiment analysis, speech recognition, and chatbots.\n",
            "\n",
            "Current Capabilities  \n",
            "- AI systems can match or exceed human-level performance at some well-defined tasks involving perception, knowledge, planning, communication, and general learning. \n",
            "- Performance remains limited for tasks involving common sense, creative problem solving, contextual adaptation, and general intelligence. \n",
            "\n",
            "Future Outlook\n",
            "- Researchers aim to make progress in developing \"general AI\" - AI at truly human-level intelligence. This remains an immense technological challenge. \n",
            "- In the nearer term, AI techniques will continue enhancing existing applications and expanding into new domains like robotics and healthcare. Careful management of risks is required.\n",
            "\n",
            "Conclusion\n",
            "- While AI has made significant advances, the quest for developing adaptable, general AI remains ongoing research with no definitive timeline. Managing ethical challenges appropriately will allow innovators to maximize benefits.\n",
            "\n",
            "Let me know if you need any clarification or would like me to expand on any specific part of this brief report.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=model,\n",
        "    output_parser=output_parser\n",
        ")\n",
        "\n",
        "# and run\n",
        "out = chain.run(topic=\"Artificial Intelligence\")\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmMP2XtExIFD"
      },
      "source": [
        "Using LCEL the format is different, rather than relying on `Chains` we simple chain together each component using the pipe operator `|`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_LOmT2aNxIFD",
        "outputId": "43c9c498-b0f4-4e46-fd2c-1973d9935214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here is a brief report on some key aspects of artificial intelligence (AI):\n",
            "\n",
            "Introduction\n",
            "- Artificial intelligence refers to computer systems that are designed to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. AI has advanced significantly in recent years due to increases in data availability, computing power, and improvements in machine learning algorithms.\n",
            "\n",
            "Current Capabilities\n",
            "- AI systems have achieved or exceeded human-level performance in some narrow domains like image classification, board games (e.g. chess and Go), and pattern recognition. AI assistants like Siri, Alexa and Google Assistant can understand natural language, answer questions, make recommendations and control smart devices. AI also shows promise for self-driving cars, healthcare, education, finance, and many business applications.  \n",
            "\n",
            "Challenges & Limitations\n",
            "- However, AI has some key limitations in terms of reasoning, common sense, planning, learning from limited data, and transferring learnings across contexts. Current AI systems also lack self-awareness and empathy. There are also concerns around bias in data and algorithms. Power consumption for training large AI models is also very intensive.\n",
            "\n",
            "Future Outlook\n",
            "- With continued advances in compute power, algorithms, and data availability, AI is expected to become more powerful and capable of addressing more complex real world problems and situations. However, the path to advanced AI or artificial general intelligence on par with human beings remains long and uncertain. Monitoring the societal impact and creating guard rails to ensure the safe development of AI will be crucial.\n",
            "\n",
            "Conclusion  \n",
            "- In summary, AI holds promise to transform many industries and improve efficiency, accuracy and personalization of products or services but still has certain limitations. Moving forward thoughtfully and deliberately in developing and deploying AI will allow us to maximize its benefits while minimizing potential harms.\n"
          ]
        }
      ],
      "source": [
        "lcel_chain = prompt | model | output_parser\n",
        "\n",
        "# and run\n",
        "out = lcel_chain.invoke({\"topic\": \"Artificial Intelligence\"})\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9A45lc8xIFD"
      },
      "source": [
        "Pretty cool, the way that this pipe operator is being used is that it is taking output from the function to the _left_ and feeding it into the function on the _right_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okbayfQOxIFD"
      },
      "source": [
        "## How the Pipe Operator Works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSQXhn_mxIFD"
      },
      "source": [
        "To really understand LCEL we can take a look at how this pipe operation works. We know it takes output from the _right_ and feeds it to the _left_ — but this isn't typical Python, so how is this implemented? Let's try creating our own version of this with some simple functions.\n",
        "\n",
        "We will be using the `__or__` method within Python class objects. When we place two classes together like `chain = class_a | class_b` the Python interpreter will check if these classes contain this `__or__` method. If they do then our `|` code will be translated into `chain = class_a.__or__(class_b)`.\n",
        "\n",
        "That means both of these patterns will return the same thing:\n",
        "\n",
        "```python\n",
        "# object approach\n",
        "chain = class_a.__or__(class_b)\n",
        "chain(\"some input\")\n",
        "\n",
        "# pipe approach\n",
        "chain = class_a | class_b\n",
        "chain(\"some input\")\n",
        "\n",
        "```\n",
        "\n",
        "With that in mind, we can build a `Runnable` class that consumes a function and turns it into a function that can be chained with other functions using the pipe operator `|`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kxd1O9xAxIFD"
      },
      "outputs": [],
      "source": [
        "class Runnable:\n",
        "    def __init__(self, func):\n",
        "        self.func = func\n",
        "\n",
        "    def __or__(self, other):\n",
        "        def chained_func(*args, **kwargs):\n",
        "            # the other func consumes the result of this func\n",
        "            return other(self.func(*args, **kwargs))\n",
        "        return Runnable(chained_func)\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.func(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoRyIwarxIFD"
      },
      "source": [
        "Let's implement this to take the value `3`, add `5` (giving `8`), and multiply by `2` (giving `16`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "st7pRuijxIFD",
        "outputId": "475e9f3b-276b-402f-9623-45f542f9601e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def add_five(x):\n",
        "    return x + 5\n",
        "\n",
        "def multiply_by_two(x):\n",
        "    return x * 2\n",
        "\n",
        "# wrap the functions with Runnable\n",
        "add_five = Runnable(add_five)\n",
        "multiply_by_two = Runnable(multiply_by_two)\n",
        "\n",
        "# run them using the object approach\n",
        "chain = add_five.__or__(multiply_by_two)\n",
        "chain(3)  # should return 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znWN1dS_xIFD"
      },
      "source": [
        "Using `__or__` directly we get the correct answer, now let's try using the pipe operator `|` to chain them together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PdXPZNe2xIFD",
        "outputId": "cae9a9a8-6118-45ee-a78e-a62a2441af58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# chain the runnable functions together\n",
        "chain = add_five | multiply_by_two\n",
        "\n",
        "# invoke the chain\n",
        "chain(3)  # we should return 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMVpr5iyxIFE"
      },
      "source": [
        "Using either method we get the same response, at it's core this is what LCEL is doing, but there is more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frTEyGQcxIFE"
      },
      "source": [
        "## LCEL Deep Dive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1PYs39oxIFE"
      },
      "source": [
        "Now that we understand what this syntax is doing under the hood, let's explore it within the context of LCEL and see a few of the additional methods that LangChain has provided to maximize flexibility when working with LCEL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG2pvy2IxIFE"
      },
      "source": [
        "### Runnables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UX9dMzqxIFE"
      },
      "source": [
        "When working with LCEL we may find that we need to modify the structure or values being passed between components — for this we can use _runnables_. Let's try:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zbBDWxHgxIFE"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import CohereEmbeddings\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "COHERE_API_KEY = \"\"\n",
        "if COHERE_API_KEY == \"<<COHERE_API_KEY>>\":\n",
        "    raise ValueError(\"Please set your COHERE_API_KEY\")\n",
        "\n",
        "embedding = CohereEmbeddings(\n",
        "    model=\"embed-english-light-v3.0\",\n",
        "    cohere_api_key=COHERE_API_KEY\n",
        ")\n",
        "\n",
        "vecstore_a = DocArrayInMemorySearch.from_texts(\n",
        "    [\"half the info will be here\", \"James' birthday is the 7th December\"],\n",
        "    embedding=embedding\n",
        ")\n",
        "vecstore_b = DocArrayInMemorySearch.from_texts(\n",
        "    [\"and half here\", \"James was born in 1994\"],\n",
        "    embedding=embedding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCUWfx_FxIFE"
      },
      "source": [
        "First let's try passing a question through to a single one of these `vecstore` objects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JjdGrMSIxIFE"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import (\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough\n",
        ")\n",
        "\n",
        "retriever_a = vecstore_a.as_retriever()\n",
        "retriever_b = vecstore_b.as_retriever()\n",
        "\n",
        "prompt_str = \"\"\"Answer the question below using the context:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer: \"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
        "\n",
        "retrieval = RunnableParallel(\n",
        "    {\"context\": retriever_a, \"question\": RunnablePassthrough()}\n",
        ")\n",
        "\n",
        "chain = retrieval | prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Nwaz07FwxIFE",
        "outputId": "57ce5bd2-6430-4c48-cc51-706b927222bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "2 validation errors for DocArrayDoc\ntext\n  Field required [type=missing, input_value={'embedding': [-0.0654296...17715454, 0.0024433136]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nmetadata\n  Field required [type=missing, input_value={'embedding': [-0.0654296...17715454, 0.0024433136]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-81690b0ef4fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"when was James born?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m                 input = step.invoke(\n\u001b[0m\u001b[1;32m   1515\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m                     \u001b[0;31m# mark each step as a child run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m                 ]\n\u001b[0;32m-> 2040\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m                 ]\n\u001b[0;32m-> 2040\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    110\u001b[0m     ) -> List[Document]:\n\u001b[1;32m    111\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         return self.get_relevant_documents(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36mget_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_retriever_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             run_manager.on_retriever_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36mget_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_other_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 result = self._get_relevant_documents(\n\u001b[0m\u001b[1;32m    205\u001b[0m                     \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\u001b[0m in \u001b[0;36m_get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    654\u001b[0m     ) -> List[Document]:\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"similarity\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"similarity_score_threshold\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             docs_and_similarities = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/docarray/base.py\u001b[0m in \u001b[0;36msimilarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mDocuments\u001b[0m \u001b[0mmost\u001b[0m \u001b[0msimilar\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search_with_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/docarray/base.py\u001b[0m in \u001b[0;36msimilarity_search_with_score\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[1;32m    105\u001b[0m         \u001b[0mquery_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mquery_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_field\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# The following line sets a flag that we use to determine when `__init__` gets overridden by the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for DocArrayDoc\ntext\n  Field required [type=missing, input_value={'embedding': [-0.0654296...17715454, 0.0024433136]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nmetadata\n  Field required [type=missing, input_value={'embedding': [-0.0654296...17715454, 0.0024433136]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing"
          ]
        }
      ],
      "source": [
        "out = chain.invoke(\"when was James born?\")\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFGVQ8GzxIFE"
      },
      "source": [
        "Here we have used `RunnableParallel` to create two parallel streams of information, one for `\"context\"` that is information fed in from `retriever_a`, and another for `\"question\"` which is the _passthrough_ information, ie the information that is passed through from our `chain.invoke(\"when was James born?\")` call.\n",
        "\n",
        "Using this information the chain is close to answering the question but it doesn't have enough information, it is missing the information that we have stored in `retriever_b`. Fortunately, we can have multiple parallel information streams using the `RunnableParallel` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMq358exxIFE"
      },
      "outputs": [],
      "source": [
        "prompt_str = \"\"\"Answer the question below using the context:\n",
        "\n",
        "Context:\n",
        "{context_a}\n",
        "{context_b}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer: \"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
        "\n",
        "retrieval = RunnableParallel(\n",
        "    {\n",
        "        \"context_a\": retriever_a, \"context_b\": retriever_b,\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        ")\n",
        "\n",
        "chain = retrieval | prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5QFZFkDxIFE",
        "outputId": "a3d1e2fa-51fd-4b63-f599-a7dde214ec75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the context provided, James was born in 1994. This is stated in the second document with the page content \"James was born in 1994\". Therefore, the answer to the question \"when was James born?\" is 1994.\n"
          ]
        }
      ],
      "source": [
        "out = chain.invoke(\"when was James born?\")\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1debZ9RMxIFE"
      },
      "source": [
        "Now the `RunnableParallel` object is allowing us to search with `retriever_a` _and_ `retriever_b` in parallel, ie at the same time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG-M4VVExIFF"
      },
      "source": [
        "## Runnable Lambdas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmt88Uw4xIFF"
      },
      "source": [
        "The `RunnableLambda` is a LangChain abstraction that allows us to turn Python functions into pipe-compatible function, similar to the `Runnable` class we created near the beginning of this notebook.\n",
        "\n",
        "Let's try it out with our earlier `add_five` and `multiply_by_two` functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzFUmJufxIFF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# wrap the functions with RunnableLambda\n",
        "add_five = RunnableLambda(add_five)\n",
        "multiply_by_two = RunnableLambda(multiply_by_two)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVGPuHdfxIFF"
      },
      "source": [
        "As with our earlier `Runnable` abstraction, we can use `|` operators to chain together our `RunnableLambda` abstractions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bv6amFkxIFF"
      },
      "outputs": [],
      "source": [
        "chain = add_five | multiply_by_two"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45myRb_exIFF"
      },
      "source": [
        "Unlike our `Runnable` abstraction, we cannot run the `RunnableLambda` chain by calling it directly, instead we must call `chain.invoke`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t58oqCEexIFF",
        "outputId": "e9b86029-0971-4640-ed94-a7d7b01f6786"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWLxljrjxIFJ"
      },
      "source": [
        "As before, we can see the same answer. Naturally we can feed custom functions into our chains using this approach. Let's try a short chain and see where we might want to insert a custom function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iltFfdBxIFJ"
      },
      "outputs": [],
      "source": [
        "prompt_str = \"Tell me an short fact about {topic}\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
        "\n",
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPhKrgpKxIFJ",
        "outputId": "50efce4a-a53d-46ab-c134-77c154f99200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" Here's a short fact about artificial intelligence:\\n\\nAI systems can analyze huge amounts of data and detect patterns that humans may miss. For example, AI is helping doctors diagnose diseases earlier by processing medical images and spotting subtle signs that a human might not notice.\""
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8vL-HVTxIFJ",
        "outputId": "956aa377-ffcb-4773-d682-8b57081c9dc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" Here's a short fact about artificial intelligence:\\n\\nAI systems are able to teach themselves over time. Through machine learning, algorithms can analyze large amounts of data and improve their own processes and decision making without needing to be manually updated by humans. This self-learning ability is a key attribute enabling AI progress.\""
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR1mhSVnxIFJ"
      },
      "source": [
        "The returned text always includes the initial `\"Here's a short fact about ...\\n\\n\"` — let's add a function to split on double newlines `\"\\n\\n\"` and only return the fact itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz_ezpTmxIFK"
      },
      "outputs": [],
      "source": [
        "def extract_fact(x):\n",
        "    if \"\\n\\n\" in x:\n",
        "        return \"\\n\".join(x.split(\"\\n\\n\")[1:])\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "get_fact = RunnableLambda(extract_fact)\n",
        "\n",
        "chain = prompt | model | output_parser | get_fact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q44dAQZvxIFK",
        "outputId": "ee78dc3a-6eff-431f-d49d-e755aeb734d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Most AI systems today are narrow AI, meaning they are focused on and trained for a specific task like computer vision, natural language processing or playing chess. General artificial intelligence that has human-level broad capabilities across many domains does not yet exist. AI has made tremendous progress in recent years thanks to advances in deep learning, big data and computing power, but still has limitations and scientists are working to make AI systems safer and more beneficial to humanity.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le6b1pWTxIFK",
        "outputId": "cd8f47d0-750b-4e0f-bff7-77792d207152"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'AI systems can analyze massive amounts of data and detect patterns that humans may miss. This ability to find insights in large datasets is one of the key strengths of AI and enables many practical applications like personalized recommendations, fraud detection, and medical diagnosis.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlh_Y_PrxIFK"
      },
      "source": [
        "Now we're getting well formatted outputs using our final custom `get_fact` function.\n",
        "\n",
        "---\n",
        "\n",
        "That covers the essentials you need to getting started and building with the **L**ang**C**hain **E**xpression **L**anguage (LCEL). With it, we can put together chains very easily — and the current focus of the LangChain team is on further LCEL development and support.\n",
        "\n",
        "The pros and cons of LCEL are varied. Those that love it tend to focus on the minimalist code style, LCEL's support for streaming, parallel operations, and async, and LCEL's nice integration with LangChain's focus on chaining components together.\n",
        "\n",
        "There are also people that are less fond of LCEL. Typically people will point to it being yet another abstraction on top of an already very abstract library, that the syntax is confusing, against [the Zen of Python](https://peps.python.org/pep-0020/), and requires too much effort to learn new (or uncommon) syntax.\n",
        "\n",
        "Both viewpoints are entirely valid, LCEL is a very different approach — ofcourse there are major pros and major cons. In either case, if you're willing to spend some time learning the syntax, it allows us to develop very quickly, and with that in mind it's well worth learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLNQgFeExIFK"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}